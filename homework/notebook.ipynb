{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 0\n",
    "\n",
    "Lectura de los datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Importar las librerias necesarias\n",
    "# import zipfile\n",
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "# # Rutas de los archivos ZIP\n",
    "# train_zip_path = os.path.join(\"../files/input\", \"train_data.csv.zip\")\n",
    "# test_zip_path = os.path.join(\"../files/input\", \"test_data.csv.zip\")\n",
    "\n",
    "# # Función para leer un CSV dentro de un archivo ZIP\n",
    "# def read_csv_from_zip(zip_path, file_name = None):\n",
    "#     with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "#         # Si no se especifica el nombre del archivo, toma el primero en el ZIP\n",
    "#         file_name = file_name or z.namelist()[0]\n",
    "#         with z.open(file_name) as f:\n",
    "#             return pd.read_csv(f)\n",
    "\n",
    "# # Leer los datasets\n",
    "# train_data = read_csv_from_zip(train_zip_path)\n",
    "# test_data = read_csv_from_zip(test_zip_path)\n",
    "\n",
    "# Importar las librerias necesarias\n",
    "import pandas as pd\n",
    "\n",
    "# Leer los datasets\n",
    "train_data = pd.read_csv(\"../files/input/train_data.csv.zip\", index_col = False, compression = \"zip\")\n",
    "test_data = pd.read_csv(\"../files/input/test_data.csv.zip\", index_col = False, compression = \"zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 1\n",
    "\n",
    "Realizar la limpieza de los datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombrar la columna \"default payment next month\" a \"default\".\n",
    "train_data = train_data.rename(columns = {'default payment next month': 'default'})\n",
    "test_data = test_data.rename(columns = {'default payment next month': 'default'})\n",
    "\n",
    "# Remover la columna \"ID\".\n",
    "train_data = train_data.drop(columns = ['ID'])\n",
    "test_data = test_data.drop(columns = ['ID'])\n",
    "\n",
    "# Eliminar los registros con informacion no disponible.\n",
    "train_data = train_data.dropna()\n",
    "test_data = test_data.dropna()\n",
    "\n",
    "# Modificar la columna 'EDUCATION' para valores > 4, agrupar en \"others\"\n",
    "train_data['EDUCATION'] = train_data['EDUCATION'].apply(lambda x: 4 if x > 4 else x)\n",
    "test_data['EDUCATION'] = test_data['EDUCATION'].apply(lambda x: 4 if x > 4 else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 2\n",
    "\n",
    "Dividir los datasets en x_train, y_train, x_test, y_tes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar en (X) variables y variable objetivo (y)\n",
    "\n",
    "# Conjunto de entrenamiento\n",
    "X_train = train_data.drop(columns = ['default'])\n",
    "y_train = train_data['default']\n",
    "\n",
    "# Conjunto de prueba\n",
    "X_test = test_data.drop(columns = ['default'])\n",
    "y_test = test_data['default']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 3\n",
    "\n",
    "Crear un pipeline para el modelo de clasificación. Este pipeline debe contener las siguientes capas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transformar las variables categoricas usando el método one-hot-encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las librerias necesarias\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Seleccionar las columnas categóricas\n",
    "categorical_columns = ['SEX', 'EDUCATION', 'MARRIAGE']\n",
    "\n",
    "# Convertir las columnas que representan categorías a tipo 'category'\n",
    "X_train[categorical_columns] = X_train[categorical_columns].astype('category')\n",
    "X_test[categorical_columns] = X_test[categorical_columns].astype('category')\n",
    "\n",
    "# Definir el transformador para las variables categóricas (One-Hot Encoding)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('cat', OneHotEncoder(), categorical_columns)\n",
    "    ],\n",
    "    remainder = 'passthrough'  # Mantener las columnas numéricas sin cambios\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ajustar un modelo de bosques aleatorios (random forest):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las librerias necesarias\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Crear el pipeline con preprocesamiento y modelo de Random Forest\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state = 38))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 4\n",
    "\n",
    "Optimizar los hiperparametros del pipeline usando validación cruzada. Usar 10 splits para la validación cruzada. Usar la función de precisión balanceada para medir la precisión del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n",
      "Mejores hiperparámetros: {'classifier__bootstrap': True, 'classifier__max_depth': None, 'classifier__max_features': 'sqrt', 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# Importar las librerias necesarias\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definir los parámetros que se van a probar en el GridSearch\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [200],                  # Número de árboles\n",
    "    'classifier__max_features': ['log2', 'sqrt', None], # Número de características a considerar en cada split\n",
    "    'classifier__max_depth': [None],                    # Profundidad máxima de los árboles\n",
    "    'classifier__min_samples_split': [10],              # Mínimo número de muestras para dividir un nodo\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],          # Mínimo número de muestras en un nodo hoja\n",
    "    'classifier__bootstrap': [True]                     # Si se usa bootstrap en la creación de los árboles\n",
    "}\n",
    "\n",
    "# Crear el objeto GridSearchCV con validación cruzada de 10 splits\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,                      # El pipeline que definimos previamente\n",
    "    param_grid,                    # Los hiperparámetros a probar\n",
    "    cv = 10,                       # Número de splits para validación cruzada\n",
    "    scoring = \"balanced_accuracy\", # Usamos precisión balanceada\n",
    "    n_jobs = -1,                   # Usar todos los núcleos disponibles\n",
    "    verbose = 1                    # Mostrar el progreso\n",
    ")\n",
    "\n",
    "# Ajustar el modelo con el conjunto de entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Guardar el mejor modelo encontrado\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Ver los mejores parámetros encontrados por GridSearch\n",
    "print(f\"Mejores hiperparámetros: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Paso 5\n",
    "\n",
    "Guardar el modelo como \"files/models/model.pkl\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado en '../files/models/model.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Importar la librería pickle\n",
    "import pickle\n",
    "\n",
    "model_path = \"../files/models/model.pkl\"\n",
    "\n",
    "# Guardar el modelo entrenado como un archivo .pkl\n",
    "with open(model_path, \"wb\") as model_file:\n",
    "    pickle.dump(best_model, model_file)\n",
    "\n",
    "print(f\"Modelo guardado en '{model_path}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Paso 6\n",
    "\n",
    "Calcular las metricas de precisión, precisión balanceada, recall, y f1-score para los conjuntos de entrenamiento y prueba. Guardarlas en el archivo files/output/metrics.json. Cada fila del archivo es un diccionario con las metricas de un modelo. \n",
    "\n",
    "Este diccionario tiene un campo para indicar si es el conjunto de entrenamiento o prueba. Por ejemplo:\n",
    "\n",
    "{'dataset': 'train', 'precision': 0.8, 'balanced_accuracy': 0.7, 'recall': 0.9, 'f1_score': 0.85}\n",
    "\n",
    "{'dataset': 'test', 'precision': 0.7, 'balanced_accuracy': 0.6, 'recall': 0.8, 'f1_score': 0.75}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas guardadas en '../files/output/metrics.json'\n"
     ]
    }
   ],
   "source": [
    "# Importar las librerias necesarias\n",
    "from sklearn.metrics import precision_score, balanced_accuracy_score, recall_score, f1_score\n",
    "import json\n",
    "\n",
    "# Hacer predicciones en los conjuntos de entrenamiento y prueba\n",
    "train_preds = best_model.predict(X_train)\n",
    "test_preds = best_model.predict(X_test)\n",
    "\n",
    "# Calcular las métricas para el conjunto de entrenamiento\n",
    "train_metrics = {\n",
    "    'type': 'metrics',\n",
    "    'dataset': 'train',\n",
    "    'precision': precision_score(y_train, train_preds),\n",
    "    'balanced_accuracy': balanced_accuracy_score(y_train, train_preds),\n",
    "    'recall': recall_score(y_train, train_preds),\n",
    "    'f1_score': f1_score(y_train, train_preds)\n",
    "}\n",
    "\n",
    "# Calcular las métricas para el conjunto de prueba\n",
    "test_metrics = {\n",
    "    'type': 'metrics',\n",
    "    'dataset': 'test',\n",
    "    'precision': precision_score(y_test, test_preds),\n",
    "    'balanced_accuracy': balanced_accuracy_score(y_test, test_preds),\n",
    "    'recall': recall_score(y_test, test_preds),\n",
    "    'f1_score': f1_score(y_test, test_preds)\n",
    "}\n",
    "\n",
    "# Crear una lista con las métricas\n",
    "metrics = [train_metrics, test_metrics]\n",
    "\n",
    "# Ruta del archivo de salida\n",
    "output_file_path = \"../files/output/metrics.json\"\n",
    "\n",
    "# Guardar las métricas en un archivo JSON\n",
    "with open(output_file_path, \"w\") as json_file:\n",
    "    json.dump(metrics, json_file)\n",
    "\n",
    "print(f\"Métricas guardadas en '{output_file_path}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Paso 7\n",
    " \n",
    "Calcular las matrices de confusión para los conjuntos de entrenamiento y prueba. Guardarlas en el archivo files/output/metrics.json. \n",
    "\n",
    "Cada fila del archivo es un diccionario con las metricas de un modelo de entrenamiento o prueba. Por ejemplo:\n",
    "\n",
    "{'type': 'cm_matrix', 'dataset': 'train', 'true_0': {\"predicted_0\": 15562, \"predicte_1\": 666}, 'true_1': {\"predicted_0\": 3333, \"predicted_1\": 1444}}\n",
    " \n",
    "{'type': 'cm_matrix', 'dataset': 'test', 'true_0': {\"predicted_0\": 15562, \"predicte_1\": 650}, 'true_1': {\"predicted_0\": 2490, \"predicted_1\": 1420}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrices de confusión guardadas en '../files/output/metrics.json'\n"
     ]
    }
   ],
   "source": [
    "# Importar las librerias necesarias\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import json\n",
    "\n",
    "# Calcular las predicciones para los conjuntos de entrenamiento y prueba\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calcular las matrices de confusión\n",
    "cm_train = confusion_matrix(y_train, y_train_pred)\n",
    "cm_test = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "# Convertir las matrices a tipos nativos de Python (int)\n",
    "cm_train = cm_train.astype(int).tolist()\n",
    "cm_test = cm_test.astype(int).tolist()\n",
    "\n",
    "# Formatear las matrices de confusión en el formato solicitado\n",
    "cm_train_dict = {\n",
    "    'type': 'cm_matrix',\n",
    "    'dataset': 'train',\n",
    "    'true_0': {\"predicted_0\": cm_train[0][0], \"predicted_1\": cm_train[0][1]},\n",
    "    'true_1': {\"predicted_0\": cm_train[1][0], \"predicted_1\": cm_train[1][1]}\n",
    "}\n",
    "\n",
    "cm_test_dict = {\n",
    "    'type': 'cm_matrix',\n",
    "    'dataset': 'test',\n",
    "    'true_0': {\"predicted_0\": cm_test[0][0], \"predicted_1\": cm_test[0][1]},\n",
    "    'true_1': {\"predicted_0\": cm_test[1][0], \"predicted_1\": cm_test[1][1]}\n",
    "}\n",
    "\n",
    "# Ruta del archivo de salida\n",
    "output_file_path = \"../files/output/metrics.json\"\n",
    "\n",
    "# Leer las métricas existentes del archivo JSON\n",
    "with open(output_file_path, 'r') as json_file:\n",
    "    existing_metrics = json.load(json_file)\n",
    "\n",
    "# Agregar las matrices de confusión a las métricas existentes\n",
    "existing_metrics.append(cm_train_dict)\n",
    "existing_metrics.append(cm_test_dict)\n",
    "\n",
    "# Guardar las métricas actualizadas en el archivo JSON\n",
    "with open(output_file_path, 'w') as json_file:\n",
    "    json.dump(existing_metrics, json_file)\n",
    "\n",
    "print(f\"Matrices de confusión guardadas en '{output_file_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'metrics',\n",
       "  'dataset': 'train',\n",
       "  'precision': 0.9717293233082707,\n",
       "  'balanced_accuracy': 0.8388718817938129,\n",
       "  'recall': 0.6835202030886397,\n",
       "  'f1_score': 0.8025335320417287},\n",
       " {'type': 'metrics',\n",
       "  'dataset': 'test',\n",
       "  'precision': 0.6586620926243568,\n",
       "  'balanced_accuracy': 0.6730886930577491,\n",
       "  'recall': 0.4023048716605553,\n",
       "  'f1_score': 0.4995121951219512},\n",
       " {'type': 'cm_matrix',\n",
       "  'dataset': 'train',\n",
       "  'true_0': {'predicted_0': 16179, 'predicted_1': 94},\n",
       "  'true_1': {'predicted_0': 1496, 'predicted_1': 3231}},\n",
       " {'type': 'cm_matrix',\n",
       "  'dataset': 'test',\n",
       "  'true_0': {'predicted_0': 6693, 'predicted_1': 398},\n",
       "  'true_1': {'predicted_0': 1141, 'predicted_1': 768}}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existing_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
